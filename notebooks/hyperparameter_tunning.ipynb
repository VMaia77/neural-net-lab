{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "from zipfile import ZipFile\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.model.neural_network import NeuralNetwork\n",
    "from src.hyperparameter_tunning.grid_search import GridSearch\n",
    "from src.utils.plots import plot_epochs_history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(0, 10, 0.1)\n",
    "\n",
    "y = np.sin(X)\n",
    "\n",
    "X = X.reshape(X.shape[0], 1)\n",
    "y = y.reshape(y.shape[0], 1)\n",
    "\n",
    "# shuffle the training dataset\n",
    "keys = np.array(range(X.shape[0]))\n",
    "np.random.shuffle(keys)\n",
    "X = X[keys]\n",
    "y = y[keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_params = dict(input_shape = X_train.shape[1], output_n_neurons = y_train.shape[1], output_activation='linear', accuracy= 'regression_mae')\n",
    "\n",
    "parameters = dict(loss = ['mean_squared_error'], optimizer = ['adam'], \n",
    "        epochs = [2000], batch_size = [None],        \n",
    "        n_layers = [2, 3, 5], n_neurons = [50, 100],  \n",
    "        learning_rate = [0.001, 0.01, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearch((X_train, y_train), NeuralNetwork,\n",
    "        start_params, parameters, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_shape</th>\n",
       "      <th>output_n_neurons</th>\n",
       "      <th>output_activation</th>\n",
       "      <th>loss</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>n_neurons</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>momentum</th>\n",
       "      <th>add_dropout</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>weights_l1_regularizer</th>\n",
       "      <th>weights_l2_regularizer</th>\n",
       "      <th>biases_l1_regularizer</th>\n",
       "      <th>biases_l2_regularizer</th>\n",
       "      <th>loss_value</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>adam</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>-0.015248</td>\n",
       "      <td>2.407562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>adam</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>-0.010569</td>\n",
       "      <td>3.707086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>adam</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.412483</td>\n",
       "      <td>-0.816549</td>\n",
       "      <td>3.888602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>adam</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.412481</td>\n",
       "      <td>-0.816544</td>\n",
       "      <td>5.639920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>adam</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.412480</td>\n",
       "      <td>-0.816538</td>\n",
       "      <td>2.973049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>adam</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.412481</td>\n",
       "      <td>-0.816544</td>\n",
       "      <td>4.340394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>adam</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.412481</td>\n",
       "      <td>-0.816544</td>\n",
       "      <td>2.487349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>adam</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.412481</td>\n",
       "      <td>-0.816544</td>\n",
       "      <td>7.534640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>adam</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.412481</td>\n",
       "      <td>-0.816544</td>\n",
       "      <td>3.462749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>adam</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011070</td>\n",
       "      <td>-0.078581</td>\n",
       "      <td>5.446443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>adam</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.114515</td>\n",
       "      <td>-0.262060</td>\n",
       "      <td>2.798545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>adam</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.303788</td>\n",
       "      <td>-0.587828</td>\n",
       "      <td>4.037327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>adam</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.114648</td>\n",
       "      <td>-0.266989</td>\n",
       "      <td>2.309352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>adam</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>-0.007778</td>\n",
       "      <td>7.128939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>adam</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010806</td>\n",
       "      <td>-0.073553</td>\n",
       "      <td>3.519616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>adam</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>-0.007711</td>\n",
       "      <td>4.731349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>adam</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.408733</td>\n",
       "      <td>-0.805329</td>\n",
       "      <td>2.794527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>adam</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.412481</td>\n",
       "      <td>-0.816544</td>\n",
       "      <td>8.083386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_shape  output_n_neurons output_activation                loss  \\\n",
       "0             1                 1            linear  mean_squared_error   \n",
       "1             1                 1            linear  mean_squared_error   \n",
       "2             1                 1            linear  mean_squared_error   \n",
       "3             1                 1            linear  mean_squared_error   \n",
       "4             1                 1            linear  mean_squared_error   \n",
       "5             1                 1            linear  mean_squared_error   \n",
       "6             1                 1            linear  mean_squared_error   \n",
       "7             1                 1            linear  mean_squared_error   \n",
       "8             1                 1            linear  mean_squared_error   \n",
       "9             1                 1            linear  mean_squared_error   \n",
       "10            1                 1            linear  mean_squared_error   \n",
       "11            1                 1            linear  mean_squared_error   \n",
       "12            1                 1            linear  mean_squared_error   \n",
       "13            1                 1            linear  mean_squared_error   \n",
       "14            1                 1            linear  mean_squared_error   \n",
       "15            1                 1            linear  mean_squared_error   \n",
       "16            1                 1            linear  mean_squared_error   \n",
       "17            1                 1            linear  mean_squared_error   \n",
       "\n",
       "   optimizer  epochs batch_size  n_layers  n_neurons  learning_rate  ...  \\\n",
       "0       adam    2000       None         2         50          0.001  ...   \n",
       "1       adam    2000       None         2        100          0.001  ...   \n",
       "2       adam    2000       None         5         50          0.100  ...   \n",
       "3       adam    2000       None         3        100          0.100  ...   \n",
       "4       adam    2000       None         3         50          0.100  ...   \n",
       "5       adam    2000       None         2        100          0.100  ...   \n",
       "6       adam    2000       None         2         50          0.100  ...   \n",
       "7       adam    2000       None         5        100          0.010  ...   \n",
       "8       adam    2000       None         5         50          0.010  ...   \n",
       "9       adam    2000       None         3        100          0.010  ...   \n",
       "10      adam    2000       None         3         50          0.010  ...   \n",
       "11      adam    2000       None         2        100          0.010  ...   \n",
       "12      adam    2000       None         2         50          0.010  ...   \n",
       "13      adam    2000       None         5        100          0.001  ...   \n",
       "14      adam    2000       None         5         50          0.001  ...   \n",
       "15      adam    2000       None         3        100          0.001  ...   \n",
       "16      adam    2000       None         3         50          0.001  ...   \n",
       "17      adam    2000       None         5        100          0.100  ...   \n",
       "\n",
       "    momentum  add_dropout  dropout_rate  weights_l1_regularizer  \\\n",
       "0        0.4            0           0.3                       0   \n",
       "1        0.4            0           0.3                       0   \n",
       "2        0.4            0           0.3                       0   \n",
       "3        0.4            0           0.3                       0   \n",
       "4        0.4            0           0.3                       0   \n",
       "5        0.4            0           0.3                       0   \n",
       "6        0.4            0           0.3                       0   \n",
       "7        0.4            0           0.3                       0   \n",
       "8        0.4            0           0.3                       0   \n",
       "9        0.4            0           0.3                       0   \n",
       "10       0.4            0           0.3                       0   \n",
       "11       0.4            0           0.3                       0   \n",
       "12       0.4            0           0.3                       0   \n",
       "13       0.4            0           0.3                       0   \n",
       "14       0.4            0           0.3                       0   \n",
       "15       0.4            0           0.3                       0   \n",
       "16       0.4            0           0.3                       0   \n",
       "17       0.4            0           0.3                       0   \n",
       "\n",
       "    weights_l2_regularizer  biases_l1_regularizer  biases_l2_regularizer  \\\n",
       "0                        0                      0                      0   \n",
       "1                        0                      0                      0   \n",
       "2                        0                      0                      0   \n",
       "3                        0                      0                      0   \n",
       "4                        0                      0                      0   \n",
       "5                        0                      0                      0   \n",
       "6                        0                      0                      0   \n",
       "7                        0                      0                      0   \n",
       "8                        0                      0                      0   \n",
       "9                        0                      0                      0   \n",
       "10                       0                      0                      0   \n",
       "11                       0                      0                      0   \n",
       "12                       0                      0                      0   \n",
       "13                       0                      0                      0   \n",
       "14                       0                      0                      0   \n",
       "15                       0                      0                      0   \n",
       "16                       0                      0                      0   \n",
       "17                       0                      0                      0   \n",
       "\n",
       "    loss_value  accuracy   runtime  \n",
       "0     0.000339 -0.015248  2.407562  \n",
       "1     0.000109 -0.010569  3.707086  \n",
       "2     0.412483 -0.816549  3.888602  \n",
       "3     0.412481 -0.816544  5.639920  \n",
       "4     0.412480 -0.816538  2.973049  \n",
       "5     0.412481 -0.816544  4.340394  \n",
       "6     0.412481 -0.816544  2.487349  \n",
       "7     0.412481 -0.816544  7.534640  \n",
       "8     0.412481 -0.816544  3.462749  \n",
       "9     0.011070 -0.078581  5.446443  \n",
       "10    0.114515 -0.262060  2.798545  \n",
       "11    0.303788 -0.587828  4.037327  \n",
       "12    0.114648 -0.266989  2.309352  \n",
       "13    0.000063 -0.007778  7.128939  \n",
       "14    0.010806 -0.073553  3.519616  \n",
       "15    0.000182 -0.007711  4.731349  \n",
       "16    0.408733 -0.805329  2.794527  \n",
       "17    0.412481 -0.816544  8.083386  \n",
       "\n",
       "[18 rows x 24 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 'mean_squared_error',\n",
       " 'optimizer': 'adam',\n",
       " 'epochs': 2000,\n",
       " 'batch_size': None,\n",
       " 'n_layers': 5,\n",
       " 'n_neurons': 100,\n",
       " 'learning_rate': 0.001}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = grid_search.get_best_params()\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(**start_params)\n",
    "\n",
    "model.set_params(**best_params)\n",
    "\n",
    "model.fit(X, y, print_every_n_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-> Acc: -0.003 Loss: 0.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.1333238844925085e-05, -0.0030830015207212757)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAlBElEQVR4nO3dfZRcdZ3n8fen0zRJqyRId9LkacJIDjMsiwlJkFnc8SEiD5lJojuG4OJyPIMdFkFx5wTjw2marB4RdgaUAaXNsItHjzHrEJIVEDGzMy7OUfNAjAFk6EGd7nSS7iCJD50YQn/3j7oVqiu3uqu6Hu7T93VOn657696qXyV963t/9/f9/q7MDOecc9nVFHUDnHPORcsDgXPOZZwHAuecyzgPBM45l3EeCJxzLuOao27ARLS1tdm8efOiboZzziXKzp07D5lZe/H6RAaCefPmsWPHjqib4ZxziSLpl2Hr/dKQc85lnAcC55zLOA8EzjmXcR4InHMu4zwQOOdcxnkgSJI9m+DuC6B7Wu73nk1Rt8i5xvC//bqqSSCQ9KCkQUl7SzwvSV+U1Ctpj6SLCp67QtLzwXPratGeNNm+9QEOdJ/LyG1TGXn4Q3CkDzA40seJLTf7AeHSb8+m3N96wd/+yMMfwm6byoHuc9m+9YGoW5h4qsU01JL+FPgt8FUzuyDk+auAm4GrgLcAXzCzt0iaBPwLcBnQD2wHrjGzZ8d6v8WLF1ua6wi2b32AObvuYroNAdCk0tuawUG103fRWpYsX9OgFjpXf/njYIYNoTGOgRED4cdBOSTtNLPFxetrUlBmZt+XNG+MTVaQCxIG/FDSNElnA/OAXjN7MWjkxmDbMQNBmm3f+gAX7Pw0U3Q899c9Dgk6GOKMnZ/mE7v62XjsEmZOm8Lay89j5cJZ9W+wc3VQyXGQP1HqYIjpO2/Fdt2Kps6BpV1w4ar6NzYFGlVZPAvoK1juD9aFrX9L2AtI6gQ6AebOnVufVkYof/azeJyzn1JadZz/bn/LZ0//IgPDbdyzeTVwowcDlyjVHgcne8/BpdNm8GBQhkYNFof9l9oY609dadZjZovNbHF7+ylTZSRa/uyng4n98ec1a4QmweymQ6xXD7sf7aldI52rs1odB3nNrx5j+PGu6l8oAxoVCPqBOQXLs4GBMdZnypxdd+W6wGUYsdy4wHhadZzbXrnHB9NcYpRzHJjljoFyTT56oMpWZUOjAsFW4L8E2UOXAEfMbD+5weH5ks6R1AKsDrbNhHxG0IxgULiU/Jf/AG18Sh/ho6/cyLC1jPv6+fGDC3Z+2oOBi61yj4Nha+Gjr9zIp/QRBmhjpIygIDM/GSpDrbKGvgG8HWgDDgK3AacBmNmXJQn4W+AKYBj4oJntCPa9CrgHmAQ8aGafHe/90pA1NGowrISxMoJeyyw6xIhEMyNjvp+BD6C52KndcTB2ht1Ra2Hvos9kPqOoVNZQTQJBo6UhEBzoPpcOSp8BVfSHG+RZN796bPxtT5sCf/5FDwYuFmp1HDzy9D6e2nw/t7CRWToUOsZwgHY6unurbXKilQoEXlkckeklusFmuT/Yis5eLlxF84p7Yeqc8JH2Qq8chW3rK2qrczUXVAqXuhxU6XGwcuEs3vqeG7m69Sslj4EZNuSXiUrwHkGDjVckU+1ZS1ldbYS6D0/4PZyrShk92GqOg5r2tlPGewQxMF563FFroe+itVW9x5Lla9i76DMcoH2M7CLz+VpcZIYf7xozCFR7HPRdtJajYyRTTNFx5uy6a8Kvn0YeCBqoVHrchC4HjWHJ8jV0dPdyS4nsIkFu3pb/8xEPBq7hSqV01uo4KOdkaLodmvDrp5EHggYqOS6A6OjurXlXdccZl7HulevpH2kLPyB8vMBFYGDkrND1+6ytZsdB/mTooMKLTwfVVvV7pIkHggYabPAf5drLz+PJSW/jrce/WHIAzY701+W9nSuWrxeYqUOn5P8PWwsbWq6t+XuGXSYaMR84LuaBoAHyB8B0GzrlAKjFuEApKxfO4nPv/ffMmjaFAQsPNgfxMyNXf4XjY03K5fvnCyX7R9rosk4WLOus+fsWXibKF6A1yYsti3kgqLOxDoBajguUsnLhLH6w7p3cdWLVKeMFw9bC546/r27v7Vxe2PhYk3KXg65u/QpvfU/9JkjMXyYaVPspBWc+cJzTqNlHM6vUAZBPj+toUDt2nHEZ634NtzZvYqZeYsDO4s4Tq9h5xmUNaoHLsuk2FDrF5Ey9xA/WvTPSNvjAsfcI6q7UAHGj//gKxwv+8Pdf584Tq/j4aZt46th7PZXU1V2jx8fi2oa48kBQZ3H54yscL1jR9BSfb9mQK8X32166BggbtK3n+Fi5bRgxmMFQ5k+GPBDUWRwOgLz8eMHnpm5mCqMvV/nc7a4e8okSi3beyjG18DJvYMTUkPGxYqcMHBMMHEPmT4Z8iok6KZwV8YjeABhT7XcMqi3y+6qOdE+jKSShdATR5FNPuBoJm+4kLtM7DH/+j2g9uv/U9VPOpvXjP4ugRY3hU0w0UHGm0Jn8hsl2nJ2LPl+XwrFKlSroKbXeuYkIS5SIS5ZOqermrN7IxgNBHcT5AADY0HJtaCppPQp6XHbFJVEijJ8MjVaTQCDpCknPS+qVtC7k+bWSdgc/eyW9KumNwXO/kPTT4Ll4X+8pU5wPAIAFyzrpsk76R9oYMdW1oMdlV1wSJcL4ydBoVQcCSZOA+4ArgfOBaySdX7iNmd1lZgvMbAHwCeCfzOxXBZu8I3j+lGtXSRTnAwBGz93+pt9/nfua3s9/a9rI8kfO97J7VzNxSpQo5idDo9WioOxioNfMXgSQtBFYATxbYvtrgG/U4H1jq++itUwNGSTrW7S2YQVk41m5cBYrF84KxjO+nGtrUHY/deen2Q6Rj2W45ClMkpijdnaftYxzfvUU0+1QLlFiUbSJEnm5KuYbufqJpQwcPsrMaVP46PSnuWTL2xh5ZIjBErfGTKuqs4Yk/QVwhZldHyx/AHiLmd0Usm0r0A+cm+8RSPo58DK52+o+YGY9Jd6nE+gEmDt37qJf/vKXVbW7LvZsys3meaSf3592BkdfGeEM+20sMoVKKXUTD7+tn6tUnLOExpPktleinllDYbeLLhVd/hz4QdFloUvN7CJyl5Y+LOlPw3Y0sx4zW2xmi9vbwy+9RCq46xJH+gDj9FeO8PpJr9D0n3pikSlUStzHM1xyxD1JYixJbnst1CIQ9ANzCpZnAwMltl1N0WUhMxsIfg8Cm8ldakqcsLsuJaFIK+7jGS45knxSkeS210ItAsF2YL6kcyS1kPuy31q8kaSpwNuALQXrXifpDfnHwLuBvTVoU8MlNS85zgN6LlmSfFKR5LbXQtWBwMxOADcBTwDPAZvM7BlJN0i6oWDT9wDfNbPfFaybATwl6SfAj4FHzew71bYpCknNSx5ddh9N6b9LhySfVCS57bXgU0zUSPdnbuPWV+6nteA647C1cOdpN9L96dsjbFllCrM+spY54ar32t/PoVgnSYRJctvLVWqw2ANBjTzy9D6e2nw/t7Dx5Hz/97C6rjfcqLWsZE64GivIlmPqbFjaBReuirpVVUnrCVGpQOA3pqmRsLzktZefl5ggAONkTqTgIHB1EGTLnUyUCGbxbIbEBoNRJ0QZqa3xQFClwjOHS9TOPQk+c/A7OLlKDT/eRWuJbLnWhAaCLJ4Q+aRzVSieZTTpN8POeuaEq1xSs+XGksVUUg8EVUhbEUrWMydc5ZKaLTeWLJ4QeSCoQtrOHDyV1FUqjbN4ZvGEyANBFdJ45rBk+Ro6untpuv0wP1zxT9zy7HzOWfcol97xDzzy9L6om+diJo2zeGbxhMgHi6uQhFlGJyqfDvtNNjLz9EMMDLdxz+bVQHLSYV39pSFbLsyS5WtODgx3BD9p5oGgCkuWr2E7jC5Cick0u9Xa/WgP69VzskButg6x3nq489FmVi5MToGcq480ZcuNJ601BYW8oMyF6u96E7ObTh3r6B9pY/b6f42gRS4uslR4mLbP6jevr6HtWx/gQPe5jNw2NbV39JrZ9FJF6112pC1bbixZ+aweCCqUttqBUo5NCb8qWmq9y460ZcuNJSuf1QNBhbJyhtB65XpOTJo8at2JSZNpvXJ9RC1ycZHGbLlSsvJZPRBUKCtnCFy4iuYV98LUOYBg6pzcckKnDXC1k6U8+6x8Vg8EFcrKGQKQ+9L/2F7oPsz2N93MgYc/mepxEVeeLOXZZ+WzetZQhdKWRVCOLH5m59KorllDkq6Q9LykXknrQp5/u6QjknYHP13l7hs3WTlDKJSVcRHnxpPWjMGqC8okTQLuAy4jdyP77ZK2mtmzRZv+PzP7swnuGytZqzr06akdZKOwaixpvk9BLXoEFwO9ZvaimR0HNgIrGrBvQ6X1TKAcmRoXcaGykjY9ljT3jGsRCGYBfQXL/cG6Yn8i6SeSHpf07yrcF0mdknZI2jE0FJ65Uy9ZPwiykjnhSkvzl2C50pwxWItAEHLRgOIR6F3AH5jZm4F7gUcq2De30qzHzBab2eL29vAz1HrJ+kGQxXERN1qavwTLleaecS0mnesH5hQszwYGCjcws18XPH5M0v2S2srZNw78Gnn2xkXcaINqp4NTg8Gg2jLzt5Dm2YZr0SPYDsyXdI6kFmA1sLVwA0kdkhQ8vjh435fK2TcO0nwm4Fw5/PJgunvGVfcIzOyEpJuAJ4BJwINm9oykG4Lnvwz8BfBfJZ0AjgKrLVfAELpvtW2qtTSfCUxE1rNHsijNU65XIq09Yy8oK9NrX37BQZDRLz8vLnMuuUoVlHkgcBU50H1u6LXiA7TT0d0bQYtcPXnvr7Qk/tuUCgR+hzJXER84z440F1BVK23/Nj7pXAlZLiAbiw+cZ0fW06bHkrZ/Gw8EIbJeQDYWzx7JDq8dKC1t/zYeCEKkLdrXUppT6Nxo3vsrLW3/Nj5GEMKvg48trSl0bjRPmy4tbf823iMIkbZo79xEeO+vtLT923j6aAjPlS9fElPonMsqTx+tgFdRlidtKXTOZZX3CNyEeXFZSu3ZBNvWw5F+mDoblnbl7l/tSkpKz9h7BK7mfFA9hfZs4sSWm2l+9Vhu+Uhfbhk8GJSQhp6xDxYX8CKyyvigevoMP971WhAINL96jOHHu0rs4dKQbu6BIOBFZJXz4rL0mXz0QEXrXTqKyzwQBNIQ1RstbSl0DgZGzqpovUtHz9gDQSANUT0KS5avoaO7l6bbD9PR3etBIOE2tFzLcFEvb9ha2NBybUQtir809IxrEggkXSHpeUm9ktaFPP+fJe0Jfv5Z0psLnvuFpJ9K2i0pslSgNER156q1YFknXdZJ/0gbIyb6R9rosk4WLOuMummxlYaecdVZQ5ImAfcBl5G7B/F2SVvN7NmCzX4OvM3MXpZ0JdADvKXg+XeYRXvqnbaScecmYuXCWcCNXP3EUgYOH2XmtCmsvfy8YL0rJenTrtQiffRioNfMXgSQtBFYAZwMBGb2zwXb/5DcTepjxYvIqpeUXGo3tpULZ/kXf8bUIhDMAvoKlvsZfbZf7C+BxwuWDfiuJAMeMLOeGrRpQpIe1aOUhlxq52rhkaf3cdcTzyeqR1WLQBBSUkRoubKkd5ALBG8tWH2pmQ1Img48KelnZvb9kH07gU6AuXPnVt9qV1NjZl15IIg9783VxiNP7+OpzffzTTYy8/RDDAy3cc/m1cCNsQ4GtRgs7gfmFCzPBgaKN5J0IbABWGFmL+XXm9lA8HsQ2EzuUtMpzKzHzBab2eL29vCBXRcdz7pKLq+hqZ3dj/awXj3MbjpEk2B20yHWq4fdj0Z2oaMstQgE24H5ks6R1AKsBrYWbiBpLvAw8AEz+5eC9a+T9Ib8Y+DdwN4atKlsXk1cG551lVxeQ1M71x//Gq1F/5atOs71x78WUYvKU3UgMLMTwE3AE8BzwCYze0bSDZJuCDbrAs4C7i9KE50BPCXpJ8CPgUfN7DvVtqlcfiZUO2nIpc4q783VzsymlypaHxc1mXTOzB4DHita9+WCx9cD14fs9yLw5uL1jeLXtWvHs66Sa1DtobPIDqrNEyYqdGxKB61H94evj6A95cr07KM+e2ZtedZVMnkNTe20Xrl+9OytwIlJk2m9cn2ErRpfpqeY8OvazqWjMjY2LlxF84p7YeocQDB1Tm455lN4Z/rGNH5LyvrxdETn4sdvTBPCr2vXhxeXOZcsme4RuPrwW1g6lxO3nrH3CFzD+CB8MsTtSyptktQzzuRgsReR1ZcPwsef19DUX5IK9TIXCPwAqD8vLou/JH1JJVWSCvUyFwj8AKg/T0eMvyR9SSVVknrGmRsj8OvXjeHFZfHm1cT1l6RCvcz1CJIUpZ2rF798V39J6hlnrkeQpCjtXL14DU1jJKVnnMk6gtfS5oIDwNPm6srTFJ2Lh1J1BJkMBK5xfBoP5+KjVCDI3BiBayzP0oqZPZvg7guge1ru955NUbcoM+Jcv5S5MQLXWJ6lFSN7No2eIvlIX24ZYj87ZtLFvcq4Jj0CSVdIel5Sr6R1Ic9L0heD5/dIuqjcfWslztE4zTxLKz6GH+8aNU8+QPOrxxh+vCuiFmVH3HvGVQcCSZOA+4ArgfOBaySdX7TZlcD84KcT+FIF+1bNq4mj42mK8TH56IGK1rvaiXsBXy16BBcDvWb2opkdBzYCK4q2WQF81XJ+CEyTdHaZ+1Yt7tE4zZKUS512AyNnVbTe1U7ce8a1CASzgL6C5f5gXTnblLMvAJI6Je2QtGNoKDy6lhL3aJx2S5avoaO7l6bbD9PR3etBICIbWq5luKh3NmwtbGi5NqIWZUfce8a1CAQhQ4EU56SW2qacfXMrzXrMbLGZLW5vD4+upcQ9GjvXCAuWddJlnfSPtDFion+kjS7rZMGyzqiblnpx7xnXImuoH5hTsDwbGChzm5Yy9q2aVxM7BysXzgJu5OonljJw+Cgzp01h7eXnBetdvcW5yrgWgWA7MF/SOcA+YDXw/qJttgI3SdoIvAU4Ymb7JQ2VsW/VvJw+XrzSODorF87yL353iqoDgZmdkHQT8AQwCXjQzJ6RdEPw/JeBx4CrgF5gGPjgWPtW26YwcY7GWRL3fGrnGmLPJti2Ho70w9TZsLQr0loOn2LCNZTfz7jxvAcWM8WFfcCJSZNpXnFv3YOBTzHhYsEzuBrLa2jiJ46FfR4IXEN5BldjeQ1N/MSxsM8DgWuouOdTp433wOInjoV9HghcQ8U9nzptvAcWP3Es7PPZR13DeQZX43gNTfwsWNZJ1+YT3GIbmamXGLCzuIfVvDXCwj4PBM6lmNfQxE8cC/s8fdRFK2b51M6lWan0Ue8RuOj4jVKciwUfLHaRiWM+tXONFoebZnmPwEUmjvnUaeHVxMkQlylXvEfgIhPHfOo08Gri5IhLwZ8HAheZOOZTp0Fcvlzc+OJS8OeBwEXGb5RSH3H5cnHji0vBn48RuMjEMZ86DQbVHjrD66DavIgsZuJS8OeBwEXKb5RSe3H5cnHji0vBnxeUOZdCr2UNBV8unjXkKF1QVlUgkPRG4JvAPOAXwCoze7lomznAV8lNKTMC9JjZF4LnuoEPwcl+7CfN7LHx3tcDQTp5yqNz9VWvG9OsA7aZ2XxgW7Bc7ATwV2b2x8AlwIclnV/w/N1mtiD4GTcIuHTylEfnolNtIFgBPBQ8fghYWbyBme03s13B498AzwF+UdiN4imPNbBnE9x9AXRPy/3esynqFrkKRVVlXG0gmGFm+yH3hQ9MH2tjSfOAhcCPClbfJGmPpAclnTnGvp2SdkjaMTQUnh7nkstTHqsUzNvEkT7ATs7b5MEgOaLsFY8bCCR9T9LekJ8VlbyRpNcDfw/cYma/DlZ/CXgTsADYD/x1qf3NrMfMFpvZ4vb28Nxbl1xxyadOKp+3Kfmi7BWPmz5qZu8q9Zykg5LONrP9ks4GBktsdxq5IPB1M3u44LUPFmzzFeDblTTepYenPFbH521Kvuk2BApbX/9ecbWXhrYC1wWPrwO2FG8gScDfAc+Z2d8UPXd2weJ7gL1VtscllN/Csjo+b1PyRdkrrjYQ3AFcJukF4LJgGUkzJeUzgC4FPgC8U9Lu4Oeq4Lk7Jf1U0h7gHcDHqmyPS7Aly9fQ0d1L0+2H6eju9SBQAZ+3Kfn6LlrL0aL/w6PWQt9Fa+v+3lVVFpvZS8DSkPUDwFXB46cI7fCAmX2gmvd3zuXE8T64rjJRVhl7ZbFzKfHI0/u464nnfd4mV5LfqtIlilcZV87nbXIT5YHAxU5c7trkXJQaeTLk9yNwseNVxuWLw/1uXe01urjMA4GLHa8yLo/Pz5RejT4Z8kDgYserjMvjPaf0avTJkAcCFztR5lMnifec0qvRJ0MeCFzseJVxebznlF6NPhnyrCEXS0uWr4Hgi78j+HGj+fxM6dXo4jIvKHMuwfyWlK4SdblVZVQ8EGSLF5c5VxteWewSyYvLnMup5wmRDxa7WPMUydG8gCyb6l0z4oHAxZqnSL7GC8iyq94nRB4IXKx5iuRrvHeUXfU+IaoqEEh6o6QnJb0Q/A69+bykXwQ3oNktaUel+7vs8uKy13jvKLvqfUJUbY9gHbDNzOYD24LlUt5hZguKRqwr2d9lkBeXvcZ7R9lV7xOiarOGVgBvDx4/BPwj8PEG7u8ywIvLcryALLvqXWBWVR2BpMNmNq1g+WUzO+XyjqSfAy8DBjxgZj2V7F/M6wiyK+t34fICMleNCdcRSPoe4Sdhn6rg/S81swFJ04EnJf3MzL5fwf5I6gQ6AebOnVvJri4lHnl6H09tvp9vspGZpx9iYLiNezavBm7MTDDw3pGrh3HHCMzsXWZ2QcjPFuCgpLMBgt+DJV5jIPg9CGwGLg6eKmv/YN8eM1tsZovb28Ovlbp02/1oD+vVw+ymQzQJZjcdYr162P1oT9RNcy7Rqh0s3gpcFzy+DthSvIGk10l6Q/4x8G5gb7n7O5d3/fGv0VqUPtmq41x//GsRtagxvIjM1Vu1geAO4DJJLwCXBctIminpsWCbGcBTkn4C/Bh41My+M9b+zoWZ2fRSRevTwIvIXCNUlTVkZi8BS0PWDwBXBY9fBN5cyf7OhTk2pYPWo/vD10fQnkYYs4jMB4ldjXhlsUuM1ivXc2LS5FHrTkyaTOuV6yNqUf15EZlrBA8ELjkuXEXzinth6hxAMHVObvnCVVG3rG68iMw1ggcClywXroKP7YXuw7C0C7ath+5pcPcFsGdT1K2rOZ9iwzWC34/AJdOeTZzYcjPNrx7LLR/pyy1DqnoIjb5locsmDwQukYYf76I1HwQCza8ey61PQSAovAnJnOAmJB3L13gRmasLDwQukSYfPVDR+iTxu7K5RvMxApdIAyNnVbQ+Sfy+A67RPBC4RNrQci3DRYOow9bChpZrI2pR7XjKqGs0DwQukRYs66TLOukfaWPERP9IG13WyYJlnVE3rWqeMuoazccIXCLlZhu9kaufWJq6Kan9vgOu0aq6H0FU/H4Erlhhls1gkGWT5IFVv++Aq4dS9yPwQOASb1SWTeCotWT2lpbOlVIqEPgYgUu8tGTZ+HTTLio+RuASb7oNgcLWJyfLxmsHXJS8R+ASLw1ZNmnp1bhk8kDgEi8NE7N57YCLUlWBQNIbJT0p6YXg95kh25wnaXfBz68l3RI81y1pX8FzV1XTHpdNS5avYe+iz3CAdkZMHKA9cQPFaejVuOSqtkewDthmZvOBbcHyKGb2vJktMLMFwCJgmNwN7PPuzj9vZo8V7+9cOZYsX0NHdy9Ntx+m76K1zNl1V6IGXdPQq3HJVe1g8Qrg7cHjh4B/BD4+xvZLgX81s19W+b7OhUraoGu+XmCRDXFEr+cYpzPVfuvTTbuGqrZHMMPM9gMEv6ePs/1q4BtF626StEfSg2GXlvIkdUraIWnH0FD49VTnkjToWnxj+jP5LZPt9+xc9Hk6uns9CLiGGTcQSPqepL0hPysqeSNJLcBy4H8XrP4S8CZgAbAf+OtS+5tZj5ktNrPF7e3h11OdS9Kga5KClku3cS8Nmdm7Sj0n6aCks81sv6SzgcExXupKYJeZHSx47ZOPJX0F+HZ5zXYu3KDa6eDUYDCottjN05OG+geXDtVeGtoKXBc8vg7YMsa211B0WSgIHnnvAfZW2R6XcUkadPVMIRcX1QaCO4DLJL0AXBYsI2mmpJMZQJJag+cfLtr/Tkk/lbQHeAfwsSrb4zKuOJX0ZV7PMZ3Oop23xi6DKElBy6WbTzrnUiuuk9EVzpR6RG8AjKn2O59l1NVdqUnnfK4hl1pjDsZG9GVbnN56Jr/hqLWwc9Hnc7UQkbTKZZ1PMeFSK44ZRJ4p5OLIA4FLrTgOxsYxODnngcClVthg7IjBDBuKbOA4jsHJOQ8ELrVGZxDlgkCTQMHUExfs/HTDgkH+pjPTbYiRovwMzxRyUfNA4FItPxndoNppKireatS1+eKpJJqUC0pmJHKmVJc+njXkMiHKKt6wAeIm5YJAR3evZwq5yHmPwGVClNfmfYDYxZ0HApcJpQaOp9dz4HjPJrj7AhTSEwEfIHbx4YHAZULhwLEVDBw31WvgeM8mTmy5GY70hV2R8gFiFyseCFxm5AeODzZg4Hj48S6aXz12ynofIHZx5IPFLnNKDRzn6wtqMd/P5KMHQteb5APELna8R+Ayp9TAcS3qC/L1AioxmePAyFkTel3n6skDgcucsIHjQlN0nIW71kH3NLj7gtygbxkK6wXCBoiHrYUNLddOsNXO1Y9fGnKZs2T5GraTy++fYeFf2s2M5B4c6ePElptzB8qFq0JfLz+t9OISr2UG+6yNe1jNW5d11upjOFczfj8Cl2kHus8NvbVlMTM4qPaT4wf5L/8ZNoTBKYPPhUZM/McpD7P28vNYuXBW7RrvXIVK3Y+gqktDkt4n6RlJI5JOefGC7a6Q9LykXknrCta/UdKTkl4Ifp9ZTXucq9R4l4ny8uMHi3beit02lUU7bz15CWisIAC5eoEfrHunBwEXW9WOEewF3gt8v9QGkiYB95G7ef35wDWSzg+eXgdsM7P5wLZg2bmGKb615Qkb+5DIT1o33pd/ntcLuCSoKhCY2XNm9vw4m10M9JrZi2Z2HNgIrAieWwE8FDx+CFhZTXucm4h8fUHT7Yf5zGkfYbiMHsJ4vF7AJUkjsoZmAX0Fy/3BOoAZZrYfIPg9vdSLSOqUtEPSjqGh8a/pOjcRC5Z10mWd9I+0MdHhs6PWwo5Fd9LR3etBwCXCuFlDkr4HofUvnzKzLWW8R1gnuuJDzMx6gB7IDRZXur9z5chdx7+Rq59YyqJfP8kdp22gtWjm0DD5ewwMqp2+RX4Depcs4wYCM3tXle/RD8wpWJ4NDASPD0o628z2SzobGKzyvZyr2sqFs4KA8E62b53HnF13nZxBtHBsIOzLv4Pwsybn4qwRdQTbgfmSzgH2AauB9wfPbQWuA+4IfpfTw3CuYZYsXwPB2X0+ZXS6HWJQbf7l71KjqjoCSe8B7gXagcPAbjO7XNJMYIOZXRVsdxVwDzAJeNDMPhusPwvYBMwF/g14n5n9arz39ToC55yrXKk6Ai8oc865jKhLQZlzzrnk80DgnHMZ54HAOecyzgOBc85lXCIHiyUNAb+c4O5twKEaNicpsvi5s/iZIZufO4ufGSr/3H9gZqfcmSmRgaAaknaEjZqnXRY/dxY/M2Tzc2fxM0PtPrdfGnLOuYzzQOCccxmXxUDQE3UDIpLFz53FzwzZ/NxZ/MxQo8+duTEC55xzo2WxR+Ccc66ABwLnnMu4TAUCSVdIel5Sr6TU3x9Z0hxJ/1fSc5KekfTRqNvUKJImSXpa0rejbkujSJom6VuSfhb8n/9J1G1qBEkfC/6+90r6hqTJUbep1iQ9KGlQ0t6CdW+U9KSkF4LfZ0709TMTCCRNAu4DrgTOB66RdH60raq7E8BfmdkfA5cAH87AZ877KPBc1I1osC8A3zGzPwLeTAY+v6RZwEeAxWZ2Abmp7ldH26q6+F/AFUXr1gHbzGw+sC1YnpDMBALgYqDXzF40s+PARmBFxG2qKzPbb2a7gse/IffFMGvsvZJP0mxgGbAh6rY0iqQzgD8F/g7AzI6b2eFIG9U4zcAUSc1AK6/dATE1zOz7QPG9WlYADwWPHwJWTvT1sxQIZgF9Bcv9ZOBLMU/SPGAh8KOIm9II9wC3AiMRt6OR/hAYAv5ncElsg6TXRd2oejOzfcD/IHdjq/3AETP7brStapgZZrYfcid9wPSJvlCWAoFC1mUid1bS64G/B24xs19H3Z56kvRnwKCZ7Yy6LQ3WDFwEfMnMFgK/o4pLBUkRXBdfAZwDzAReJ+naaFuVPFkKBP3AnILl2aSwC1lM0mnkgsDXzezhqNvTAJcCyyX9gtzlv3dK+lq0TWqIfqDfzPI9vm+RCwxp9y7g52Y2ZGavAA8D/yHiNjXKQUlnAwS/Byf6QlkKBNuB+ZLOkdRCbkBpa8RtqitJInfN+Dkz+5uo29MIZvYJM5ttZvPI/R//g5ml/gzRzA4AfZLOC1YtBZ6NsEmN8m/AJZJag7/3pWRgkDywFbgueHwdsGWiL9Rck+YkgJmdkHQT8AS5zIIHzeyZiJtVb5cCHwB+Kml3sO6TZvZYdE1ydXQz8PXgROdF4IMRt6fuzOxHkr4F7CKXJfc0KZxuQtI3gLcDbZL6gduAO4BNkv6SXEB834Rf36eYcM65bMvSpSHnnHMhPBA451zGeSBwzrmM80DgnHMZ54HAOecyzgOBc85lnAcC55zLuP8PoSoS8XxZ34IAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model.predict(X)\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.scatter(X, pred)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn_math",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76a5504535aef6b067c4c319349625057dcd6affdbc57273f2f09881b7291f0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
